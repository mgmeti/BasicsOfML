{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "MnYKrUwimN8R",
        "xhhW1ncqSXol",
        "zxb6KE7UmVrN"
      ],
      "authorship_tag": "ABX9TyNRkKFpnHmikpjr4TIrKZqR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mgmeti/BasicsOfML/blob/main/knn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "QSWc0WoEHqsK"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ### KNN from Scratch"
      ],
      "metadata": {
        "id": "T6id1MONE69O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class KNNClassifier:\n",
        "    def __init__(self, k=3):\n",
        "        self.k = k\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "\n",
        "    def predict(self, x):\n",
        "        distances = [self.euclidean_distance(x, x_train) for _, x_train in self.X_train.iterrows()]\n",
        "        k_neighbors_indices = np.argsort(distances)[:self.k]\n",
        "        k_neighbor_labels = [self.y_train.iloc[i] for i in k_neighbors_indices]\n",
        "        most_common = Counter(k_neighbor_labels).most_common(1)\n",
        "        return most_common[0][0]\n",
        "\n",
        "    def euclidean_distance(self, row1, row2):\n",
        "        distance = 0.0\n",
        "        for i in range(len(row1)):\n",
        "            if isinstance(row1[i], str) and isinstance(row2[i], str):\n",
        "                distance += int(row1[i] != row2[i])\n",
        "            else:\n",
        "                distance += (float(row1[i]) - float(row2[i]))**2\n",
        "        return np.sqrt(distance)\n"
      ],
      "metadata": {
        "id": "CqYA9pFfySoq"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tune_k_knn(X, y, k_values):\n",
        "    best_k = None\n",
        "    best_accuracy = 0.0\n",
        "    best_classifier = None\n",
        "\n",
        "    for k in k_values:\n",
        "        knn_classifier = KNNClassifier(k=k)\n",
        "        X_train, X_cv, y_train, y_cv = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "        knn_classifier.fit(X_train, y_train)\n",
        "\n",
        "        # Perform cross-validation and get accuracy\n",
        "        predictions_cv = [knn_classifier.predict(x) for _, x in X_cv.iterrows()]\n",
        "        accuracy_cv = accuracy_score(y_cv, predictions_cv)\n",
        "\n",
        "        if accuracy_cv > best_accuracy:\n",
        "            best_accuracy = accuracy_cv\n",
        "            best_k = k\n",
        "            best_classifier = knn_classifier\n",
        "\n",
        "    return best_k, best_classifier\n"
      ],
      "metadata": {
        "id": "9oAXTqNY45ee"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def k_fold_cross_validation_knn(knn_classifier, X, y, k_folds=5):\n",
        "    n = len(X)\n",
        "    fold_size = n // k_folds\n",
        "    indices = np.arange(n)\n",
        "\n",
        "    accuracies = []\n",
        "\n",
        "    for i in range(k_folds):\n",
        "        test_indices = indices[i * fold_size:(i + 1) * fold_size]\n",
        "        train_indices = np.concatenate([indices[:i * fold_size], indices[(i + 1) * fold_size:]])\n",
        "\n",
        "        X_train, X_test = X.iloc[train_indices], X.iloc[test_indices]\n",
        "        y_train, y_test = y.iloc[train_indices], y.iloc[test_indices]\n",
        "\n",
        "        knn_classifier.fit(X_train, y_train)\n",
        "        predictions = [knn_classifier.predict(x) for _, x in X_test.iterrows()]\n",
        "\n",
        "        accuracy_fold = accuracy_score(y_test, predictions)\n",
        "        accuracies.append(accuracy_fold)\n",
        "\n",
        "    return np.mean(accuracies)"
      ],
      "metadata": {
        "id": "lijeNy-pHanN"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "omgpVLYeHdCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ### Implementation"
      ],
      "metadata": {
        "id": "Vtgii09VHd1y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ### car"
      ],
      "metadata": {
        "id": "MnYKrUwimN8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Step 1: Read CSV into DataFrame without column names\n",
        "file_path = '/content/car.csv'  # Replace with the path to your CSV file\n",
        "df1 = pd.read_csv(file_path, header=None)\n",
        "\n",
        "# Step 2: Print the head of the DataFrame\n",
        "print(\"Original DataFrame:\")\n",
        "print(df1.head())\n",
        "\n",
        "# Step 3: Remove NA values\n",
        "df1 = df1.dropna()\n",
        "\n",
        "# Step 4: Assign column names (you can replace these with your actual column names)\n",
        "column_names = [\"buying\", \"maint\", \"doors\", \"persons\", \"lug_boot\", \"safety\",\"class\"]  # Replace with your column names\n",
        "df1.columns = column_names\n",
        "\n",
        "# Step 5: Encode categorical values\n",
        "le = LabelEncoder()\n",
        "for column in df1.columns:\n",
        "    if df1[column].dtype == 'object':  # Check if the column contains categorical values\n",
        "        df1[column] = le.fit_transform(df1[column])\n",
        "\n",
        "# Step 6: Print head of the cleaned and encoded DataFrame\n",
        "print(\"\\nDataFrame after cleaning and encoding:\")\n",
        "print(df1.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZIpypvyheXA",
        "outputId": "45788b54-25d6-4f68-ab52-a61b533a1ed4"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrame:\n",
            "       0      1  2  3      4     5      6\n",
            "0  vhigh  vhigh  2  2  small   low  unacc\n",
            "1  vhigh  vhigh  2  2  small   med  unacc\n",
            "2  vhigh  vhigh  2  2  small  high  unacc\n",
            "3  vhigh  vhigh  2  2    med   low  unacc\n",
            "4  vhigh  vhigh  2  2    med   med  unacc\n",
            "\n",
            "DataFrame after cleaning and encoding:\n",
            "   buying  maint  doors  persons  lug_boot  safety  class\n",
            "0       3      3      0        0         2       1      2\n",
            "1       3      3      0        0         2       2      2\n",
            "2       3      3      0        0         2       0      2\n",
            "3       3      3      0        0         1       1      2\n",
            "4       3      3      0        0         1       2      2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract features (X) and target (y)\n",
        "X = df1.drop('class', axis=1)  # Drop the 'Class' column to get features\n",
        "y = df1['class']  # Target variable\n",
        "\n",
        "# Calculate mean and standard deviation for each feature\n",
        "means = X.mean()\n",
        "std_devs = X.std()\n",
        "\n",
        "# Normalize features manually to have mean 0 and variance 1\n",
        "X_normalized = (X - means) / std_devs\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.25, random_state=42)\n",
        "\n",
        "\n",
        "# Specify a range of k values to tune\n",
        "k_values_to_tune = [1, 3, 5, 7, 9]\n",
        "\n",
        "# Perform tuning and get the best k and classifier\n",
        "best_k, best_classifier = tune_k_knn(X_train, y_train, k_values_to_tune)\n",
        "\n",
        "# Use the best classifier to make predictions on X_test\n",
        "# (Assuming X_test is already defined)\n",
        "predictions_test = [best_classifier.predict(x) for _, x in X_test.iterrows()]\n",
        "\n",
        "# Calculate accuracy\n",
        "best_accuracy = accuracy_score(y_test, predictions_test)\n",
        "\n",
        "print(f\"Best k: {best_k}\")\n",
        "print(f\"Best Accuracy: {best_accuracy:.2f}\")\n",
        "print(f\"Predictions on X_test: {predictions_test}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed77c304-c701-4307-bbf3-d48ad79ef646",
        "id": "wyklapPkPlM6"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best k: 5\n",
            "Best Accuracy: 0.92\n",
            "Predictions on X_test: [2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 1, 2, 0, 2, 2, 0, 3, 2, 0, 0, 2, 2, 2, 2, 2, 1, 3, 2, 2, 2, 2, 3, 2, 2, 2, 3, 0, 2, 0, 3, 3, 2, 1, 2, 2, 2, 1, 2, 2, 2, 0, 0, 2, 2, 2, 2, 0, 0, 2, 2, 0, 2, 2, 2, 2, 2, 0, 1, 2, 2, 2, 2, 3, 2, 0, 0, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 3, 2, 2, 2, 2, 0, 0, 2, 0, 2, 2, 2, 2, 0, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2, 0, 3, 0, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 3, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 3, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 3, 2, 2, 0, 0, 2, 0, 2, 0, 0, 2, 2, 0, 1, 3, 0, 2, 2, 2, 2, 2, 3, 0, 0, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 3, 0, 0, 2, 2, 2, 0, 0, 2, 3, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 2, 2, 3, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 0, 2, 0, 1, 3, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 0, 2, 2, 3, 2, 0, 2, 2, 0, 0, 2, 3, 2, 0, 0, 1, 2, 2, 0, 2, 2, 2, 2, 0, 2, 0, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Extract features (X) and target (y)\n",
        "X = df1.drop('class', axis=1)\n",
        "y = df1['class']\n",
        "\n",
        "\n",
        "\n",
        "# Normalize features using scikit-learn's StandardScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# Perform k-fold cross-validation using scikit-learn\n",
        "knn_classifier = KNeighborsClassifier()\n",
        "cv_scores = cross_val_score(knn_classifier, X_normalized, y, cv=10)\n",
        "\n",
        "# Print mean accuracy across folds\n",
        "print(f\"Mean Accuracy with 10-fold Cross-Validation: {np.mean(cv_scores):.2f}\")\n",
        "\n",
        "# Tune k using GridSearchCV\n",
        "param_grid = {'n_neighbors': [1, 3, 5, 7, 9]}\n",
        "grid_search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best k from grid search\n",
        "best_k = grid_search.best_params_['n_neighbors']\n",
        "print(f\"Best k: {best_k}\")\n",
        "\n",
        "# Make predictions on the test set using the best model\n",
        "best_model = grid_search.best_estimator_\n",
        "predictions_test_skl = best_model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy on the test set\n",
        "accuracy_test = accuracy_score(y_test, predictions_test_skl)\n",
        "print(f\"Accuracy on the Test Set: {accuracy_test:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d18e84c-3706-41e0-875f-779a5d95527c",
        "id": "NUVwpjGxPlM7"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Accuracy with 10-fold Cross-Validation: 0.83\n",
            "Best k: 5\n",
            "Accuracy on the Test Set: 0.92\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paired t-test\n",
        "t_stat, p_value = ttest_rel(predictions_test, predictions_test_skl)\n",
        "\n",
        "# Interpret the results\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis. There is a significant difference.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis. There is no significant difference.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ceb2560-bb6e-404f-ae81-a9dd46d58aa8",
        "id": "4CTYhSwAPlM7"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reject the null hypothesis. There is a significant difference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HOQPqaa_SXSI"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ### cancer"
      ],
      "metadata": {
        "id": "xhhW1ncqSXol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 1: Read CSV into DataFrame without column names\n",
        "file_path = '/content/breast-cancer.csv'  # Replace with the path to your CSV file\n",
        "df2 = pd.read_csv(file_path, header=None)\n",
        "\n",
        "# Step 2: Print the head of the DataFrame\n",
        "print(\"Original DataFrame:\")\n",
        "print(df2.head())\n",
        "\n",
        "# Step 3: Remove NA values\n",
        "df2 = df2.dropna()\n",
        "\n",
        "# Step 4: Assign column names (you can replace these with your actual column names)\n",
        "column_names = [\n",
        "    'class',\n",
        "    'age',\n",
        "    'menopause',\n",
        "    'tumor-size',\n",
        "    'inv-nodes',\n",
        "    'node-caps',\n",
        "    'deg-malig',\n",
        "    'breast',\n",
        "    'breast-quad',\n",
        "    'irradiat'\n",
        "]\n",
        "df2.columns = column_names\n",
        "\n",
        "# Step 5: Encode categorical values\n",
        "le = LabelEncoder()\n",
        "for column in df2.columns:\n",
        "    if df2[column].dtype == 'object':  # Check if the column contains categorical values\n",
        "        df2[column] = le.fit_transform(df2[column])\n",
        "\n",
        "# Step 6: Print head of the cleaned and encoded DataFrame\n",
        "print(\"\\nDataFrame after cleaning and encoding:\")\n",
        "print(df2.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be7ae5dd-8387-4638-beb9-5232c172c79a",
        "id": "l-Ro7OBfSXol"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrame:\n",
            "                      0      1        2      3    4   5  6      7          8  \\\n",
            "0  no-recurrence-events  30-39  premeno  30-34  0-2  no  3   left   left_low   \n",
            "1  no-recurrence-events  40-49  premeno  20-24  0-2  no  2  right   right_up   \n",
            "2  no-recurrence-events  40-49  premeno  20-24  0-2  no  2   left   left_low   \n",
            "3  no-recurrence-events  60-69     ge40  15-19  0-2  no  2  right    left_up   \n",
            "4  no-recurrence-events  40-49  premeno    0-4  0-2  no  2  right  right_low   \n",
            "\n",
            "    9  \n",
            "0  no  \n",
            "1  no  \n",
            "2  no  \n",
            "3  no  \n",
            "4  no  \n",
            "\n",
            "DataFrame after cleaning and encoding:\n",
            "   class  age  menopause  tumor-size  inv-nodes  node-caps  deg-malig  breast  \\\n",
            "0      0    1          2           5          0          1          3       0   \n",
            "1      0    2          2           3          0          1          2       1   \n",
            "2      0    2          2           3          0          1          2       0   \n",
            "3      0    4          0           2          0          1          2       1   \n",
            "4      0    2          2           0          0          1          2       1   \n",
            "\n",
            "   breast-quad  irradiat  \n",
            "0            2         0  \n",
            "1            5         0  \n",
            "2            2         0  \n",
            "3            3         0  \n",
            "4            4         0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract features (X) and target (y)\n",
        "X = df2.drop('class', axis=1)  # Drop the 'Class' column to get features\n",
        "y = df2['class']  # Target variable\n",
        "\n",
        "# Calculate mean and standard deviation for each feature\n",
        "means = X.mean()\n",
        "std_devs = X.std()\n",
        "\n",
        "# Normalize features manually to have mean 0 and variance 1\n",
        "X_normalized = (X - means) / std_devs\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.25, random_state=42)\n",
        "\n",
        "\n",
        "# Specify a range of k values to tune\n",
        "k_values_to_tune = [1, 3, 5, 7, 9]\n",
        "\n",
        "# Perform tuning and get the best k and classifier\n",
        "best_k, best_classifier = tune_k_knn(X_train, y_train, k_values_to_tune)\n",
        "\n",
        "# Use the best classifier to make predictions on X_test\n",
        "# (Assuming X_test is already defined)\n",
        "predictions_test = [best_classifier.predict(x) for _, x in X_test.iterrows()]\n",
        "\n",
        "# Calculate accuracy\n",
        "best_accuracy = accuracy_score(y_test, predictions_test)\n",
        "\n",
        "print(f\"Best k: {best_k}\")\n",
        "print(f\"Best Accuracy: {best_accuracy:.2f}\")\n",
        "print(f\"Predictions on X_test: {predictions_test}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8820f78-534f-4ab6-d08c-dfd81afe193e",
        "id": "QHncCUDUQwlx"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best k: 7\n",
            "Best Accuracy: 0.67\n",
            "Predictions on X_test: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Extract features (X) and target (y)\n",
        "X = df2.drop('class', axis=1)\n",
        "y = df2['class']\n",
        "\n",
        "\n",
        "\n",
        "# Normalize features using scikit-learn's StandardScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# Perform k-fold cross-validation using scikit-learn\n",
        "knn_classifier = KNeighborsClassifier()\n",
        "cv_scores = cross_val_score(knn_classifier, X_normalized, y, cv=10)\n",
        "\n",
        "# Print mean accuracy across folds\n",
        "print(f\"Mean Accuracy with 10-fold Cross-Validation: {np.mean(cv_scores):.2f}\")\n",
        "\n",
        "# Tune k using GridSearchCV\n",
        "param_grid = {'n_neighbors': [1, 3, 5, 7, 9]}\n",
        "grid_search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best k from grid search\n",
        "best_k = grid_search.best_params_['n_neighbors']\n",
        "print(f\"Best k: {best_k}\")\n",
        "\n",
        "# Make predictions on the test set using the best model\n",
        "best_model = grid_search.best_estimator_\n",
        "predictions_test_skl = best_model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy on the test set\n",
        "accuracy_test = accuracy_score(y_test, predictions_test_skl)\n",
        "print(f\"Accuracy on the Test Set: {accuracy_test:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f28d6cf-91de-4514-f6b8-5890b82e8b68",
        "id": "AfdpKrqSQwly"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Accuracy with 10-fold Cross-Validation: 0.69\n",
            "Best k: 7\n",
            "Accuracy on the Test Set: 0.67\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paired t-test\n",
        "t_stat, p_value = ttest_rel(predictions_test, predictions_test_skl)\n",
        "\n",
        "# Interpret the results\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis. There is a significant difference.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis. There is no significant difference.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f2b2084-6635-47da-eef3-cbb41ee97931",
        "id": "kH7_ZapaQwly"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fail to reject the null hypothesis. There is no significant difference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ### roth"
      ],
      "metadata": {
        "id": "zxb6KE7UmVrN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 1: Read CSV into DataFrame without column names\n",
        "file_path = '/content/hayes-roth.csv'  # Replace with the path to your CSV file\n",
        "df3 = pd.read_csv(file_path, header=None)\n",
        "\n",
        "# Step 2: Print the head of the DataFrame\n",
        "print(\"Original DataFrame:\")\n",
        "print(df3.head())\n",
        "\n",
        "# Step 3: Remove NA values\n",
        "df3 = df3.dropna()\n",
        "\n",
        "# Step 4: Assign column names (you can replace these with your actual column names)\n",
        "\n",
        "column_names\n",
        "\n",
        "column_names = [\n",
        "    'name',\n",
        "    'hobby',\n",
        "    'age',\n",
        "    'educational_level',\n",
        "    'marital_status',\n",
        "    'class'\n",
        "]\n",
        "\n",
        "df3.columns = column_names\n",
        "\n",
        "# Step 5: Encode categorical values\n",
        "le = LabelEncoder()\n",
        "for column in df3.columns:\n",
        "    if df3[column].dtype == 'object':  # Check if the column contains categorical values\n",
        "        df3[column] = le.fit_transform(df3[column])\n",
        "\n",
        "# Step 6: Print head of the cleaned and encoded DataFrame\n",
        "print(\"\\nDataFrame after cleaning and encoding:\")\n",
        "print(df3.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZ-10mFLkjor",
        "outputId": "4e7df916-995f-4e6d-dd50-d381ee5ebaa0"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrame:\n",
            "     0  1  2  3  4  5\n",
            "0   92  2  1  1  2  1\n",
            "1   10  2  1  3  2  2\n",
            "2   83  3  1  4  1  3\n",
            "3   61  2  4  2  2  3\n",
            "4  107  1  1  3  4  3\n",
            "\n",
            "DataFrame after cleaning and encoding:\n",
            "   name  hobby  age  educational_level  marital_status  class\n",
            "0    92      2    1                  1               2      1\n",
            "1    10      2    1                  3               2      2\n",
            "2    83      3    1                  4               1      3\n",
            "3    61      2    4                  2               2      3\n",
            "4   107      1    1                  3               4      3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract features (X) and target (y)\n",
        "X = df3.drop('class', axis=1)  # Drop the 'Class' column to get features\n",
        "y = df3['class']  # Target variable\n",
        "\n",
        "# Calculate mean and standard deviation for each feature\n",
        "means = X.mean()\n",
        "std_devs = X.std()\n",
        "\n",
        "# Normalize features manually to have mean 0 and variance 1\n",
        "X_normalized = (X - means) / std_devs\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.25, random_state=42)\n",
        "\n",
        "\n",
        "# Specify a range of k values to tune\n",
        "k_values_to_tune = [1, 3, 5, 7, 9]\n",
        "\n",
        "# Perform tuning and get the best k and classifier\n",
        "best_k, best_classifier = tune_k_knn(X_train, y_train, k_values_to_tune)\n",
        "\n",
        "# Use the best classifier to make predictions on X_test\n",
        "# (Assuming X_test is already defined)\n",
        "predictions_test = [best_classifier.predict(x) for _, x in X_test.iterrows()]\n",
        "\n",
        "# Calculate accuracy\n",
        "best_accuracy = accuracy_score(y_test, predictions_test)\n",
        "\n",
        "print(f\"Best k: {best_k}\")\n",
        "print(f\"Best Accuracy: {best_accuracy:.2f}\")\n",
        "print(f\"Predictions on X_test: {predictions_test}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIWLBYPrzn73",
        "outputId": "5708bba5-842d-4d22-dad5-2674053bc6d7"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best k: 1\n",
            "Best Accuracy: 0.58\n",
            "Predictions on X_test: [2, 2, 2, 2, 1, 2, 2, 2, 3, 1, 1, 2, 1, 3, 3, 1, 2, 2, 1, 2, 2, 2, 1, 3, 3, 1, 1, 2, 2, 1, 1, 3, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sk-learn"
      ],
      "metadata": {
        "id": "L1XRlQBWM11_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Extract features (X) and target (y)\n",
        "X = df3.drop('class', axis=1)\n",
        "y = df3['class']\n",
        "\n",
        "\n",
        "\n",
        "# Normalize features using scikit-learn's StandardScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# Perform k-fold cross-validation using scikit-learn\n",
        "knn_classifier = KNeighborsClassifier()\n",
        "cv_scores = cross_val_score(knn_classifier, X_normalized, y, cv=10)\n",
        "\n",
        "# Print mean accuracy across folds\n",
        "print(f\"Mean Accuracy with 10-fold Cross-Validation: {np.mean(cv_scores):.2f}\")\n",
        "\n",
        "# Tune k using GridSearchCV\n",
        "param_grid = {'n_neighbors': [1, 3, 5, 7, 9]}\n",
        "grid_search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best k from grid search\n",
        "best_k = grid_search.best_params_['n_neighbors']\n",
        "print(f\"Best k: {best_k}\")\n",
        "\n",
        "# Make predictions on the test set using the best model\n",
        "best_model = grid_search.best_estimator_\n",
        "predictions_test_skl = best_model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy on the test set\n",
        "accuracy_test = accuracy_score(y_test, predictions_test_skl)\n",
        "print(f\"Accuracy on the Test Set: {accuracy_test:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeT1sEOcMF17",
        "outputId": "29084bdb-6d98-4239-9196-5f0aff10242c"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Accuracy with 10-fold Cross-Validation: 0.43\n",
            "Best k: 1\n",
            "Accuracy on the Test Set: 0.61\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paired t-test\n",
        "t_stat, p_value = ttest_rel(predictions_test, predictions_test_skl)\n",
        "\n",
        "# Interpret the results\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis. There is a significant difference.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis. There is no significant difference.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWOv_mXJMrG5",
        "outputId": "d225d2b7-028d-421f-d32e-770cec656ed7"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fail to reject the null hypothesis. There is no significant difference.\n"
          ]
        }
      ]
    }
  ]
}